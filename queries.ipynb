{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import os\n",
    "from weaviate.classes.init import AdditionalConfig, Timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "client = weaviate.connect_to_wcs(\n",
    "    cluster_url=os.getenv(\"WCD_URL\"),\n",
    "    auth_credentials=weaviate.auth.AuthApiKey(os.getenv(\"WCD_API_KEY\")),\n",
    "    headers={\n",
    "        \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_APIKEY\"]\n",
    "    },\n",
    "    additional_config=AdditionalConfig(timeout=Timeout(init=10, query=45, insert=120))\n",
    ")\n",
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the collection\n",
    "collection_of_docs = client.collections.get(\"Documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AggregateReturn(properties={}, total_count=104)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many chunks?\n",
    "collection_of_docs.aggregate.over_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'management systems, includ-\\ning NoSQL and relational databases, are not designed for these\\ndatasets and workloads. First, vector queries rely on the concept of\\nsimilarity which can be vague for different applications, requiring\\na different query specification. Second, similarity computation is\\nmore expensive than other types of comparisons seen in relational\\npredicates, requiring efficient techniques. Third, processing a vector\\nquery often requires retrieving full vectors from the collection.', 'source': 'Quickstart Competitive Analysis.pdf'}\n",
      "{'content': 'Vector Database Management Techniques and Systems\\nJianguo Wang\\ncsjgwang@purdue.edu\\nPurdue University\\nWest Lafayette, Indiana, USA\\nJames Jie Pan\\njamesjpan@tsinghua.edu.cn\\nTsinghua University\\nBeijing, China\\nGuoliang Li\\nliguoliang@tsinghua.edu.cn\\nTsinghua University\\nBeijing, China\\nABSTRACT\\nFeature vectors are now mission-critical for many applications, in-\\ncluding retrieval-based large language models (LLMs). Traditional\\ndatabase management systems are not equipped to deal with the\\nunique', 'source': 'Quickstart Competitive Analysis.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# Semantic Search, print items in response objects. len = limit.\n",
    "response = collection_of_docs.query.near_text(\n",
    "        query=\"error handling\",\n",
    "        limit=2\n",
    "    )\n",
    "for item in response.objects:\n",
    "    print(item.properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " managing and querying large amounts of data efficiently. The Management of Data conference, organized by SIGMOD, focuses on addressing the challenges and opportunities in managing and querying large-scale data, particularly high-dimensional feature vectors.\n",
      "\n",
      "The conference will take place from June 9â€“15, 2024, in Santiago, AA, Chile. The event will feature presentations, workshops, and discussions on the latest research and developments in data management. Researchers, practitioners, and industry experts from around the world will come together to share their insights and experiences in handling large datasets.\n",
      "\n",
      "Topics that will be covered at the conference include but are not limited to:\n",
      "\n",
      "- Efficient indexing and querying of high-dimensional feature vectors\n",
      "- Scalable storage and retrieval techniques for large datasets\n",
      "- Machine learning and deep learning approaches for data management\n",
      "- Data cleaning, preprocessing, and transformation\n",
      "- Query optimization and performance tuning\n",
      "- Data privacy and security in large-scale data management\n",
      "\n",
      "The conference proceedings will be published by ACM in New York, NY, USA, and will consist of 8 pages. Participants can also access the papers and presentations online through the DOI link provided (https://doi.org/10.1145/3626246.3654691).\n",
      "\n",
      "Overall, the Management of Data conference aims to bring together experts in the field to discuss and explore innovative solutions for managing and querying large-scale data effectively. It provides a platform for researchers and practitioners to exchange ideas, collaborate on new projects, and advance the state-of-the-art in data management.\n",
      "retrieve vectors based on specific criteria, such as finding all vectors that are similar to a given query vector. More complex search queries may involve finding vectors that are similar to multiple query vectors or finding vectors that are similar to a combination of query vectors.\n",
      "\n",
      "In order to effectively handle these types of queries, a VDBMS must support basic operators such as similarity search, nearest neighbor search, and range search. These operators allow users to retrieve vectors based on their similarity to other vectors or based on their position within a specified range.\n",
      "\n",
      "However, the effectiveness of these operators can be limited by the curse of dimensionality, which refers to the increased difficulty of measuring distances accurately in high-dimensional spaces. In such cases, alternative scoring methods may be necessary to compensate for the limitations of distance-based scores.\n",
      "\n",
      "Overall, the ambiguity and complexity of data manipulation and search queries in a VDBMS require careful consideration and resolution before a suitable scoring method can be selected. Additionally, the curse of dimensionality may further complicate the selection process, necessitating the use of alternative scoring methods to ensure accurate and efficient query processing.\n"
     ]
    }
   ],
   "source": [
    "# Generative Search with single prompt. Need a for loop to parse through limit amount of chunks that generate.near_text() returns.\n",
    "response = collection_of_docs.generate.near_text(\n",
    "        query=\"high dimensional vector\",\n",
    "        single_prompt=\"Explain {content} very directly\",\n",
    "        limit=2\n",
    "    )\n",
    "for item in response.objects:\n",
    "    print(item.generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The content discusses how traditional database management systems, including NoSQL and relational databases, are not designed to handle datasets and workloads that involve vector queries. Vector queries rely on the concept of similarity, which can be vague and require different query specifications. Similarity computation is more expensive than other types of comparisons, and processing a vector query often requires retrieving full vectors from the collection. The abstract of the source paper mentions that feature vectors are crucial for many applications, such as retrieval-based large language models, and traditional database management systems are not equipped to handle them.\n"
     ]
    }
   ],
   "source": [
    "# Generative Search with grouped task. Only one response, since the limit amount of chunks are combined, so only need to return one thing.\n",
    "response = collection_of_docs.generate.near_text(\n",
    "        query=\"error handling\",\n",
    "        grouped_task=\"Please summarize this content\",\n",
    "        limit=2\n",
    "    )\n",
    "print(response.generated)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('myenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf1d52e68f29d02c820ab8695fce3ef0cc30a0acc768515361d644b4141ef940"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
